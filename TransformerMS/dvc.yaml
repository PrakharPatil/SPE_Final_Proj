stages:
  data_import:
    cmd: python scripts/data_import.py
    deps:
      - scripts/data_import.py
    params:
      - data_import.file_size
    outs:
      - Data/Raw
  data_preprocessing:
    cmd: python scripts/data_preprocessing.py
    deps:
      - Data/Raw
      - scripts/data_preprocessing.py
    outs:
      - Data/Clean
  tokenizer:
    cmd: python scripts/tokenizer.py
    deps:
      - Data/Clean
      - scripts/tokenizer.py
    params:
      - tokenizer.vocab_size
    outs:
      - Joblibs/tokenizer.joblib
  transformer_training:
    cmd: PYTHONPATH=/Users/prakhar_patil/Desktop/SPE_Proj python scripts/transformer_training.py
    deps:
      - scripts/transformer_training.py
      - Model/model_architecture.py
      - Joblibs/tokenizer.joblib
      - Data/Clean
    outs:
      - checkpoints/
#  model_evaluation:
#    cmd: python scripts/model_evaluation.py
#    deps:
#      - checkpoints/gpt_model.pth
#      - Joblibs/tokenizer.joblib
#      - scripts/model_evaluation.py
#      - Model/model_architecture.py
#    outs:
#      - Reports/metrics.json
#      - Logs/evaluation.log

